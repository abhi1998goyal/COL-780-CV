{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision.transforms import functional as F\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2          \n",
    "import time\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from transformers import DeformableDetrForObjectDetection, AutoImageProcessor\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection, DetrConfig\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torchvision.transforms as T\n",
    "!pip install transformers --upgrade\n",
    "!pip install pycocotools\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "def load_model(checkpoint_path):\n",
    "    model = DeformableDetrForObjectDetection.from_pretrained(\"SenseTime/deformable-detr\")\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model\n",
    "\n",
    "def visualize_predictions(image, logits, pred_boxes, threshold=0.8):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "#     print(type(image))\n",
    "    width, height = image.size\n",
    "    logits = logits.cpu()\n",
    "    pred_boxes = pred_boxes.cpu()\n",
    "#     print(image.type)\n",
    "\n",
    "#     scores = logits.softmax(-1).max(-1).values\n",
    "#     print(logits)\n",
    "\n",
    "    for box, score  in zip(pred_boxes, logits):\n",
    "        if score.item() > threshold:\n",
    "            x1, y1, w, h = box\n",
    "            x1=x1*width\n",
    "            w=w*width\n",
    "            y1=y1*height\n",
    "            h=h*height\n",
    "            x1=x1-w/2\n",
    "            y1=y1-h/2\n",
    "            x2, y2 = x1 + w, y1 + h\n",
    "            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "#             score_str = \"{:.2f}\".format(score.item())\n",
    "#             plt.text(x1, y1, score_str, color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    checkpoint_path = \"/kaggle/input/deformable-detr/model.pt\"\n",
    "    model = load_model(checkpoint_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "    # Define the image folder and get a list of images\n",
    "    img_folder='/kaggle/input/cv-a4-coco-dataset/coco_1k/val2017'\n",
    "    image_files = [os.path.join(img_folder, img) for img in os.listdir(img_folder) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Process images one by one\n",
    "    i=0\n",
    "    for image_path in image_files:\n",
    "        i+=1\n",
    "        image = Image.open(image_path)\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs['pixel_values'])\n",
    "        logits = outputs['logits']\n",
    "        pred_boxes = outputs['pred_boxes']\n",
    "        logits = torch.nn.functional.softmax(logits, dim=2)\n",
    "        print(logits.shape)\n",
    "        print(pred_boxes.shape)\n",
    "        tensor_np = logits.cpu().numpy()\n",
    "\n",
    "        # Find the indices of maximum values along axis 2 (last axis)\n",
    "        max_indices = tensor_np.argmax(axis=2)\n",
    "\n",
    "        # Check if the maximum value is at the 0th position\n",
    "        keep_indices = (max_indices == 0)\n",
    "\n",
    "        # Convert the keep indices back to a PyTorch tensor\n",
    "        keep_indices_tensor = torch.tensor(keep_indices, dtype=torch.bool)\n",
    "\n",
    "        # Filter the tensor and pred_boxes using the keep indices\n",
    "        filtered_logits = logits[keep_indices_tensor]\n",
    "        filtered_pred_boxes = pred_boxes[keep_indices_tensor.unsqueeze(2).expand_as(pred_boxes)].view(-1, 4)\n",
    "\n",
    "        # Print the filtered tensor and pred_boxes\n",
    "#         print(\"Filtered tensor:\", filtered_logits)\n",
    "        print(filtered_logits.shape)\n",
    "        filtered_logits = filtered_logits[:, 0].unsqueeze(1)\n",
    "#         print(\"Filtered tensor:\", filtered_logits)\n",
    "#         print(\"Filtered pred_boxes:\", filtered_pred_boxes)\n",
    "        print(filtered_logits.shape)\n",
    "        print(filtered_pred_boxes.shape)\n",
    "        # Convert outputs to CPU for visualization if on GPU\n",
    "#         outputs = {k: v.to('cpu') for k, v in outputs.items()}\n",
    "#         print(outputs)\n",
    "        visualize_predictions(image, filtered_logits, filtered_pred_boxes)\n",
    "#         if(i>3):\n",
    "#             break\n",
    "        break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
